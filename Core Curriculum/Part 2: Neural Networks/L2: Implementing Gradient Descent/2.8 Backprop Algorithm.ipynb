{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.8 Backprop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtSKRYWW049e",
        "colab_type": "text"
      },
      "source": [
        "# Goal\n",
        "Now you're going to implement the backprop algorithm for a network trained on the graduate school admission data. You should have everything you need from the previous exercises to complete this one.\n",
        "\n",
        "Your goals here:\n",
        "\n",
        "* Implement the forward pass.\n",
        "* Implement the backpropagation algorithm.\n",
        "* Update the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhU2yQL91VGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_prep.py \n",
        "# helper script\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "admissions = pd.read_csv('binary.csv')\n",
        "\n",
        "# Make dummy variables for rank\n",
        "data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
        "data = data.drop('rank', axis=1)\n",
        "\n",
        "# Standarize features\n",
        "for field in ['gre', 'gpa']:\n",
        "    mean, std = data[field].mean(), data[field].std()\n",
        "    data.loc[:,field] = (data[field]-mean)/std\n",
        "    \n",
        "# Split off random 10% of the data for testing\n",
        "np.random.seed(21)\n",
        "sample = np.random.choice(data.index, size=int(len(data)*0.9), replace=False)\n",
        "data, test_data = data.iloc[sample], data.drop(sample)\n",
        "\n",
        "# Split into features and targets\n",
        "features, targets = data.drop('admit', axis=1), data['admit']\n",
        "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBHU-_Jv3_7t",
        "colab_type": "text"
      },
      "source": [
        "# Step by Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GBrloe-4UrN",
        "colab_type": "text"
      },
      "source": [
        "# Preliminaries\n",
        "First, we do the:\n",
        "* import(s)\n",
        "* function(s) needed\n",
        "* Hyperparameters needed to be **set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORElrIB24Re3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(21)\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calculate sigmoid\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WERlzvooAqVM",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIbPK5NuApu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden = 2  # number of hidden units\n",
        "epochs = 900\n",
        "learnrate = 0.005\n",
        "\n",
        "n_records, n_features = features.shape\n",
        "last_loss = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCcTKPGD4yoe",
        "colab_type": "text"
      },
      "source": [
        "# Initialize weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V16WVZPy4zGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
        "                                        size=(n_features, n_hidden))\n",
        "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
        "                                         size=n_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2jt4vnQ4_gg",
        "colab_type": "text"
      },
      "source": [
        "## Main algorithm:\n",
        "\n",
        "*For each epoch:*\n",
        "\n",
        "**Forward Pass**\n",
        " 1. Calculate the output, $y$ \n",
        "\n",
        "**Output Error Term, $\\delta_0$**\n",
        " 2. Calculate the network's prediction error:\n",
        " $$ \\hat{y} - y$$\n",
        " where $\\hat{y}$ is the target and $y$ is the actual output\n",
        "\n",
        " 3. Calculate ,$ \\delta_0$:\n",
        " $$\\delta_0 = (\\hat{y} - y)[(y)(1-y)]$$\n",
        "in words:\n",
        "$$Output Error Term = Network's Prediction Error * f'(h)$$\n",
        "\n",
        "**Backprop**\n",
        "\n",
        "*Calculate Values*\n",
        "*Note: Our goal is to provide the values needed for the weight update*\n",
        " 3. $W \\delta_0$, Calculate the hidden layer's contribution to the error \n",
        " 4. $\\delta_j$, Calculate the error term for the hidden layer:\n",
        " $$\\delta_j = W\\delta_0(y_{hiddenoutput})(1-y_{hiddenoutput})$$\n",
        " 5. $\\Delta w$, Update the change in weights\n",
        " $$\\Delta w_{hiddenoutput} += \\delta_0 * y_{hiddenoutput} $$\n",
        "$$\\Delta w_{inputhidden} +=\\delta_j * y_{inputhidden}$$\n",
        "\n",
        "*Update Weights*\n",
        "6. Update all weights\n",
        "$$w_{inputhidden} += (a* \\Delta w_{inputhidden})(\\frac{1}{n})$$\n",
        "$$w_{hiddenoutput} += (a* \\Delta w_{hiddenoutput})(\\frac{1}{n})$$\n",
        "where *a* is the learning rate and *n* is the number of records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cLAl90M4_qb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "b93dd408-9d1b-40d1-a99e-47dd7d14353d"
      },
      "source": [
        "for e in range(epochs):\n",
        "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
        "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
        "    for x, y in zip(features.values, targets):\n",
        "        ## Forward pass ##\n",
        "        # TODO: Calculate the output\n",
        "        hidden_input = np.dot(x, weights_input_hidden)\n",
        "        hidden_output = sigmoid(hidden_input)\n",
        "\n",
        "        output = sigmoid(np.dot(hidden_output,\n",
        "                                weights_hidden_output))\n",
        "\n",
        "        ## Backward pass ##\n",
        "        # TODO: Calculate the network's prediction error\n",
        "        error = y - output\n",
        "\n",
        "        # TODO: Calculate error term for the output unit\n",
        "        output_error_term = error * output * (1 - output)\n",
        "\n",
        "        ## propagate errors to hidden layer\n",
        "\n",
        "        # TODO: Calculate the hidden layer's contribution to the error\n",
        "        hidden_error = np.dot(output_error_term, weights_hidden_output)\n",
        "\n",
        "        # TODO: Calculate the error term for the hidden layer\n",
        "        hidden_error_term = hidden_error * hidden_output * (1 - hidden_output)\n",
        "\n",
        "        # TODO: Update the change in weights\n",
        "        del_w_hidden_output += output_error_term * hidden_output\n",
        "        del_w_input_hidden += hidden_error_term * x[:, None]\n",
        "\n",
        "    # TODO: Update weights\n",
        "    weights_input_hidden += learnrate * del_w_input_hidden / n_records\n",
        "    weights_hidden_output += learnrate * del_w_hidden_output / n_records\n",
        "\n",
        "    # Printing out the mean square error on the training set\n",
        "    if e % (epochs / 10) == 0:\n",
        "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
        "        out = sigmoid(np.dot(hidden_output,\n",
        "                             weights_hidden_output))\n",
        "        loss = np.mean((out - targets) ** 2)\n",
        "\n",
        "        if last_loss and last_loss < loss:\n",
        "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
        "        else:\n",
        "            print(\"Train loss: \", loss)\n",
        "        last_loss = loss\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train loss:  0.25135725242598617\n",
            "Train loss:  0.24996540718842886\n",
            "Train loss:  0.24862005218904654\n",
            "Train loss:  0.24731993217179746\n",
            "Train loss:  0.24606380465584848\n",
            "Train loss:  0.24485044179257162\n",
            "Train loss:  0.2436786320186832\n",
            "Train loss:  0.24254718151769536\n",
            "Train loss:  0.24145491550165465\n",
            "Train loss:  0.24040067932493367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMhmJEHHA_M_",
        "colab_type": "text"
      },
      "source": [
        "## Calculate Accuracy on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4TvhwkcBDDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1190bb74-b51f-46f1-a31b-851c009d8400"
      },
      "source": [
        "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
        "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
        "predictions = out > 0.5\n",
        "accuracy = np.mean(predictions == targets_test)\n",
        "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction accuracy: 0.725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsejxH4u4Ml2",
        "colab_type": "text"
      },
      "source": [
        "# The Whole Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6WX32Cj0Ac-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "ce21d70e-fb55-4960-bf6e-f04ed9d37eff"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(21)\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calculate sigmoid\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "n_hidden = 2  # number of hidden units\n",
        "epochs = 900\n",
        "learnrate = 0.005\n",
        "\n",
        "n_records, n_features = features.shape\n",
        "last_loss = None\n",
        "# Initialize weights\n",
        "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
        "                                        size=(n_features, n_hidden))\n",
        "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
        "                                         size=n_hidden)\n",
        "\n",
        "for e in range(epochs):\n",
        "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
        "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
        "    for x, y in zip(features.values, targets):\n",
        "        ## Forward pass ##\n",
        "        # TODO: Calculate the output\n",
        "        hidden_input = np.dot(x, weights_input_hidden)\n",
        "        hidden_output = sigmoid(hidden_input)\n",
        "\n",
        "        output = sigmoid(np.dot(hidden_output,\n",
        "                                weights_hidden_output))\n",
        "\n",
        "        ## Backward pass ##\n",
        "        # TODO: Calculate the network's prediction error\n",
        "        error = y - output\n",
        "\n",
        "        # TODO: Calculate error term for the output unit\n",
        "        output_error_term = error * output * (1 - output)\n",
        "\n",
        "        ## propagate errors to hidden layer\n",
        "\n",
        "        # TODO: Calculate the hidden layer's contribution to the error\n",
        "        hidden_error = np.dot(output_error_term, weights_hidden_output)\n",
        "\n",
        "        # TODO: Calculate the error term for the hidden layer\n",
        "        hidden_error_term = hidden_error * hidden_output * (1 - hidden_output)\n",
        "\n",
        "        # TODO: Update the change in weights\n",
        "        del_w_hidden_output += output_error_term * hidden_output\n",
        "        del_w_input_hidden += hidden_error_term * x[:, None]\n",
        "\n",
        "    # TODO: Update weights\n",
        "    weights_input_hidden += learnrate * del_w_input_hidden / n_records\n",
        "    weights_hidden_output += learnrate * del_w_hidden_output / n_records\n",
        "\n",
        "    # Printing out the mean square error on the training set\n",
        "    if e % (epochs / 10) == 0:\n",
        "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
        "        out = sigmoid(np.dot(hidden_output,\n",
        "                             weights_hidden_output))\n",
        "        loss = np.mean((out - targets) ** 2)\n",
        "\n",
        "        if last_loss and last_loss < loss:\n",
        "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
        "        else:\n",
        "            print(\"Train loss: \", loss)\n",
        "        last_loss = loss\n",
        "\n",
        "# Calculate accuracy on test data\n",
        "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
        "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
        "predictions = out > 0.5\n",
        "accuracy = np.mean(predictions == targets_test)\n",
        "print(\"Prediction accuracy: {:.3f}\".format(accuracy))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train loss:  0.25135725242598617\n",
            "Train loss:  0.24996540718842886\n",
            "Train loss:  0.24862005218904654\n",
            "Train loss:  0.24731993217179746\n",
            "Train loss:  0.24606380465584848\n",
            "Train loss:  0.24485044179257162\n",
            "Train loss:  0.2436786320186832\n",
            "Train loss:  0.24254718151769536\n",
            "Train loss:  0.24145491550165465\n",
            "Train loss:  0.24040067932493367\n",
            "Prediction accuracy: 0.725\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}