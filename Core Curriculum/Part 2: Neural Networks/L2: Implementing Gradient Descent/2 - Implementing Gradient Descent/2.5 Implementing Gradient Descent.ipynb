{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.5 Implementing Gradient Descent.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdljhnjbhjTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "0516bfcf-edeb-439e-f709-2654f0f28cea"
      },
      "source": [
        "import numpy as np\n",
        "from data_prep import features, targets, features_test, targets_test\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calculate sigmoid\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# TODO: We haven't provided the sigmoid_prime function like we did in\n",
        "#       the previous lesson to encourage you to come up with a more\n",
        "#       efficient solution. If you need a hint, check out the comments\n",
        "#       in solution.py from the previous lecture.\n",
        "\n",
        "# Use to same seed to make debugging easier\n",
        "np.random.seed(42)\n",
        "\n",
        "n_records, n_features = features.shape\n",
        "last_loss = None\n",
        "\n",
        "# Initialize weights\n",
        "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
        "\n",
        "# Neural Network hyperparameters\n",
        "epochs = 1000\n",
        "learnrate = 0.5\n",
        "\n",
        "for e in range(epochs):\n",
        "    del_w = np.zeros(weights.shape)\n",
        "    for x, y in zip(features.values, targets):\n",
        "        # Loop through all records, x is the input, y is the target\n",
        "\n",
        "        # Note: We haven't included the h variable from the previous\n",
        "        #       lesson. You can add it if you want, or you can calculate\n",
        "        #       the h together with the output\n",
        "\n",
        "        # TODO: Calculate the output\n",
        "        output = sigmoid(np.dot(x,weights))\n",
        "\n",
        "        # TODO: Calculate the error\n",
        "        error = y - output\n",
        "\n",
        "        # TODO: Calculate the error term\n",
        "        error_term = error * (sigmoid(output)*(1-sigmoid(output)))\n",
        "\n",
        "        # TODO: Calculate the change in weights for this sample\n",
        "        #       and add it to the total weight change\n",
        "        del_w += error_term*x\n",
        "\n",
        "    # TODO: Update weights using the learning rate and the average change in weights\n",
        "    weights += learnrate*del_w*(1/features.shape[0])\n",
        "\n",
        "    # Printing out the mean square error on the training set\n",
        "    if e % (epochs / 10) == 0:\n",
        "        out = sigmoid(np.dot(features, weights))\n",
        "        loss = np.mean((out - targets) ** 2)\n",
        "        if last_loss and last_loss < loss:\n",
        "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
        "        else:\n",
        "            print(\"Train loss: \", loss)\n",
        "        last_loss = loss\n",
        "\n",
        "\n",
        "# Calculate accuracy on test data\n",
        "tes_out = sigmoid(np.dot(features_test, weights))\n",
        "predictions = tes_out > 0.5\n",
        "accuracy = np.mean(predictions == targets_test)\n",
        "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data_prep.py:18: FutureWarning: \n",
            ".ix is deprecated. Please use\n",
            ".loc for label based indexing or\n",
            ".iloc for positional indexing\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
            "  data, test_data = data.ix[sample], data.drop(sample)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss:  0.26278611572698024\n",
            "Train loss:  0.20937141149954802\n",
            "Train loss:  0.20044288410978808\n",
            "Train loss:  0.19823345349235758\n",
            "Train loss:  0.19750695385368605\n",
            "Train loss:  0.19721983653958547\n",
            "Train loss:  0.1970933007462839\n",
            "Train loss:  0.197033828341473\n",
            "Train loss:  0.1970047768586571\n",
            "Train loss:  0.19699025948140808\n",
            "Prediction accuracy: 0.725\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}