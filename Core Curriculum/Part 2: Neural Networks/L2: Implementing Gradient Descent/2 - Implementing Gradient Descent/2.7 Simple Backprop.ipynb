{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.7 Simple Backprop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35V7IUmZyBH7",
        "colab_type": "text"
      },
      "source": [
        "Below, you'll implement the code to calculate one backpropagation update step for two sets of weights. I wrote the forward pass - your goal is to code the backward pass.\n",
        "\n",
        "Things to do:\n",
        "* Calculate the network's output error. (lambda_0)\n",
        "* Calculate the output layer's error term. (lambda_1)\n",
        "* Use backpropagation to calculate the hidden layer's error term. (lambda_2)\n",
        "* Calculate the change in weights (the delta weights) that result from propagating the errors back through the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhFPQR-mx1_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f36514dd-a462-42c9-cfe1-5eed91718c75"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calculate sigmoid\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "x = np.array([0.5, 0.1, -0.2])\n",
        "target = 0.6\n",
        "learnrate = 0.5\n",
        "\n",
        "weights_input_hidden = np.array([[0.5, -0.6],\n",
        "                                 [0.1, -0.2],\n",
        "                                 [0.1, 0.7]])\n",
        "\n",
        "weights_hidden_output = np.array([0.1, -0.3])\n",
        "\n",
        "## Forward pass\n",
        "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
        "hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "\n",
        "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "output = sigmoid(output_layer_in)\n",
        "\n",
        "## Backwards pass\n",
        "## TODO: Calculate output error\n",
        "error = target - output # lambda_0 = y_hat - y \n",
        "\n",
        "# TODO: Calculate error term for output layer\n",
        "output_error_term = error * output * (1 - output) # lambda_1 = lambda_0 * ( y * (1-y)) = lambda_0 * f'(h2)\n",
        "output_error_term = np.dot(output_error_term, weights_hidden_output)\n",
        "print(len(output_error_term))\n",
        "\n",
        "# TODO: Calculate error term for hidden layer\n",
        "hidden_error_term =  output_error_term * hidden_layer_output * (1 - hidden_layer_output)\n",
        "# lambda_2 = lambda_1 * f'(h1)\n",
        "\n",
        "# === done computing errors ====\n",
        "# == update the weights == \n",
        "# TODO: Calculate change in weights for hidden layer to output layer\n",
        "delta_w_h_o = learnrate * output_error_term * hidden_layer_output\n",
        "\n",
        "# TODO: Calculate change in weights for input layer to hidden layer\n",
        "delta_w_i_h = learnrate * hidden_error_term * x[:, None]\n",
        "\n",
        "print('Change in weights for hidden layer to output layer:')\n",
        "print(delta_w_h_o)\n",
        "print('Change in weights for input layer to hidden layer:')\n",
        "print(delta_w_i_h)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "Change in weights for hidden layer to output layer:\n",
            "[ 0.00080405 -0.00166775]\n",
            "Change in weights for input layer to hidden layer:\n",
            "[[ 1.77005547e-04 -5.11178506e-04]\n",
            " [ 3.54011093e-05 -1.02235701e-04]\n",
            " [-7.08022187e-05  2.04471402e-04]]\n",
            "ERROR! Session/line number was not unique in database. History logging moved to new session 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbozUZMS1mjt",
        "colab_type": "text"
      },
      "source": [
        "Change in weights for hidden layer to output layer:\n",
        "[0.00804047 0.00555918]\n",
        "Change in weights for input layer to hidden layer:\n",
        "[[ 1.77005547e-04 -5.11178506e-04]\n",
        " [ 3.54011093e-05 -1.02235701e-04]\n",
        " [-7.08022187e-05  2.04471402e-04]]\n",
        "\n",
        "Nice job!  That's right!"
      ]
    }
  ]
}